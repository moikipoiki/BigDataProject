parameter = list(supp = 0.1, conf = 0.1, target = "rules")
)
return(rules_all)
}
# Update JobsFeed
updateJobs <- function(df){
new_df = crawlJobs()
for(i in 1:nrow(new_df)) {
if(!(new_df$id[i] %in% df$id) & !(new_df$id[i]=="null")){
cat("adding new ID",fill = TRUE)
app = c(toString(new_df$id[1]),
toString(new_df$author[1]),
toString(new_df$date[1]),
toString(new_df$title[1]),
toString(new_df$category[1]),
toString(new_df$city[1]),
toString(new_df$country[1]))
df <- rbind(df,app)
}
}
return(df)
}
# Crawls Stackoverflow for jobs
crawlJobs <- function(){
# Dictionary for translating certain locations to English
city_transl <- c("MUENCHEN",
"KOELN",
"FRANKFURT",
"MALMO",
"GENEVE",
"KIEV",
"ZUERICH",
"MILAN",
"WARSZAWA")
names(city_transl) <- c("münchen",
"köln",
"frankfurt am Main",
"malmö",
"genève",
"kyiv",
"zürich",
"milano",
"warsaw")
# get JobsFeed from Stackoverflow
link <- "https://stackoverflow.com/jobs/feed"
html <- getURL(link, followlocation = TRUE)
doc = htmlParse(html, asText=TRUE)
len = length(xpathSApply(doc, "//item", xmlValue))
author = c()
date = c()
title = c()
category = c()
location = c()
city = c()
country  = c()
id = c()
for(i in 1:len){
item = paste("//item[",i,"]/",sep="")
tit = xpathSApply(doc, paste(item,"title",sep=""), xmlValue)
cat = xpathSApply(doc, paste(item,"category",sep=""), xmlValue)
loc = xpathSApply(doc, paste(item,"location",sep=""), xmlValue)
aut = xpathSApply(doc, paste(item,"author/name",sep=""), xmlValue)
upd = xpathSApply(doc, paste(item,"updated",sep=""), xmlValue)
iden = xpathSApply(doc, paste(item,"guid",sep=""), xmlValue)
cou = "null"
cit = "null"
# skip tuple values if there is no location or category provided
if (length(loc)==0 | length(cat)==0 ){
tit = "null"
cat = "null"
loc = "null"
aut = "null"
upd = "null"
iden = "null"
}
# concatenate all category vaulues to one string
else{
cat_2 = c()
for(x in cat){
cat_2 = c(cat_2,str_replace_all(x,"[^[:alpha:]]",""))
}
cat = paste(cat_2, collapse = ';')
cit = toupper(strsplit(loc,split=", ")[[1]][1])
cou = toupper(strsplit(loc,split=", ")[[1]][2])
# print(cit)
# translate city if possible
if(!is.na(city_transl[tolower(cit)])){
cit = city_transl[tolower(cit)]
}
}
id[i] = iden
author[i] = aut
date[i] = upd
title[i] = tit
category[i] = cat
#location[i] = loc
city[i] = cit
country[i] = cou
}
# write to data.frame and export as csv
df = data.frame(id,author,date,title,category,city,country,stringsAsFactors=FALSE)
return(df)
}
df = c()
drops <- c("X.1","X")
# Main
if(!file.exists("data/jobsFeed.csv")){
cat("No Job Database existing.",fill = TRUE)
cat("Initialising Jobs.",fill = TRUE)
df = df[ , !(names(df) %in% drops)]
df = crawlJobs()
}else{
cat("Job Database existing.",fill = TRUE)
df = read.csv("data/jobsFeed.csv")
cat("Updating Jobs.",fill = TRUE)
df = df[ , !(names(df) %in% drops)]
df = updateJobs(df=df)
}
write.csv(df, file = "data/jobsFeed.csv")
rules <- associationRuleMining()
inspect(rules)
library(XML)
library(curl)
library(RCurl)
library(sparklyr)
library(dplyr)
library(stringr)
library(arules)
setwd("/Users/michaelstedler/PycharmProjects/BigDataProject")
# Association Rule Mining
# @return: set of association rules
associationRuleMining <- function(){
# Spark Configurations
conf <- spark_config()
# build SPARK Connection
sc <- spark_connect(master = "local")
# load dataframe
jobsFeed <- read.csv("data/jobsFeed.csv")
tbl_jobsFeed <- copy_to(sc,jobsFeed,name=spark_table_name(substitute(jobsFeed)))
#
x <- tbl_jobsFeed %>%
#filter(city=="BERLIN") %>%
select(author,category,city,country)%>%
collect()
# build list with all categories in filtered jobsFeed
categories <- c()
for(i in 1:length(x$category)){
ls = strsplit(x$category[i],split = ";")
for(cat in ls[[1]]){
if(!cat %in% categories){
categories <-c(categories,str_replace_all(cat,"[^[:alpha:]]",""))
}
}
}
# create columns for every possible language
mydf <- data.frame(x$author,
x$city,
x$country,
x$category)
for (i in categories) {
print(i)
eval(parse(text = paste0('mydf$',i,' <- rep(FALSE,length(x$category))')))
}
# load true for every language in inserat
for(i in 1:length(x$category)){
ls = strsplit(x$category[i],split = ";")
for(cat in ls[[1]]){
if(cat %in% categories){
eval(parse(text = paste0('mydf$',cat,'[',i,'] <- TRUE')))
}
}
}
# perform Assiociation Rules
rules_all <- apriori(mydf,
parameter = list(supp = 0.1,
conf = 0.1,
target = "rules",
minlen=2)
)
return(rules_all)
}
# Update JobsFeed
updateJobs <- function(df){
new_df = crawlJobs()
for(i in 1:nrow(new_df)) {
if(!(new_df$id[i] %in% df$id) & !(new_df$id[i]=="null")){
cat("adding new ID",fill = TRUE)
app = c(toString(new_df$id[1]),
toString(new_df$author[1]),
toString(new_df$date[1]),
toString(new_df$title[1]),
toString(new_df$category[1]),
toString(new_df$city[1]),
toString(new_df$country[1]))
df <- rbind(df,app)
}
}
return(df)
}
# Crawls Stackoverflow for jobs
crawlJobs <- function(){
# Dictionary for translating certain locations to English
city_transl <- c("MUENCHEN",
"KOELN",
"FRANKFURT",
"MALMO",
"GENEVE",
"KIEV",
"ZUERICH",
"MILAN",
"WARSZAWA")
names(city_transl) <- c("münchen",
"köln",
"frankfurt am Main",
"malmö",
"genève",
"kyiv",
"zürich",
"milano",
"warsaw")
# get JobsFeed from Stackoverflow
link <- "https://stackoverflow.com/jobs/feed"
html <- getURL(link, followlocation = TRUE)
doc = htmlParse(html, asText=TRUE)
len = length(xpathSApply(doc, "//item", xmlValue))
author = c()
date = c()
title = c()
category = c()
location = c()
city = c()
country  = c()
id = c()
for(i in 1:len){
item = paste("//item[",i,"]/",sep="")
tit = xpathSApply(doc, paste(item,"title",sep=""), xmlValue)
cat = xpathSApply(doc, paste(item,"category",sep=""), xmlValue)
loc = xpathSApply(doc, paste(item,"location",sep=""), xmlValue)
aut = xpathSApply(doc, paste(item,"author/name",sep=""), xmlValue)
upd = xpathSApply(doc, paste(item,"updated",sep=""), xmlValue)
iden = xpathSApply(doc, paste(item,"guid",sep=""), xmlValue)
cou = "null"
cit = "null"
# skip tuple values if there is no location or category provided
if (length(loc)==0 | length(cat)==0 ){
tit = "null"
cat = "null"
loc = "null"
aut = "null"
upd = "null"
iden = "null"
}
# concatenate all category vaulues to one string
else{
cat_2 = c()
for(x in cat){
cat_2 = c(cat_2,str_replace_all(x,"[^[:alpha:]]",""))
}
cat = paste(cat_2, collapse = ';')
cit = toupper(strsplit(loc,split=", ")[[1]][1])
cou = toupper(strsplit(loc,split=", ")[[1]][2])
# print(cit)
# translate city if possible
if(!is.na(city_transl[tolower(cit)])){
cit = city_transl[tolower(cit)]
}
}
id[i] = iden
author[i] = aut
date[i] = upd
title[i] = tit
category[i] = cat
#location[i] = loc
city[i] = cit
country[i] = cou
}
# write to data.frame and export as csv
df = data.frame(id,author,date,title,category,city,country,stringsAsFactors=FALSE)
return(df)
}
df = c()
drops <- c("X.1","X")
# Main
if(!file.exists("data/jobsFeed.csv")){
cat("No Job Database existing.",fill = TRUE)
cat("Initialising Jobs.",fill = TRUE)
df = df[ , !(names(df) %in% drops)]
df = crawlJobs()
}else{
cat("Job Database existing.",fill = TRUE)
df = read.csv("data/jobsFeed.csv")
cat("Updating Jobs.",fill = TRUE)
df = df[ , !(names(df) %in% drops)]
df = updateJobs(df=df)
}
write.csv(df, file = "data/jobsFeed.csv")
rules <- associationRuleMining()
inspect(rules)
library(sparklyr)
library(dplyr)
library(stringr)
library(arules)
setwd("/Users/michaelstedler/PycharmProjects/BigDataProject")
# Spark Configurations
conf <- spark_config()
# build SPARK Connection
sc <- spark_connect(master = "local")
# load dataframe
jobsFeed <- read.csv("data/jobsFeed.csv")
tbl_jobsFeed <- copy_to(sc,jobsFeed,name=spark_table_name(substitute(jobsFeed)))
#
x <- tbl_jobsFeed %>%
#filter(city=="BERLIN") %>%
select(author,category,city,country)%>%
collect()
# build list with all categories in filtered jobsFeed
categories <- c()
for(i in 1:length(x$category)){
ls = strsplit(x$category[i],split = ";")
for(cat in ls[[1]]){
if(!cat %in% categories){
categories <-c(categories,str_replace_all(cat,"[^[:alnum:]]",""))
}
}
}
# create columns for every possible language
mydf <- data.frame(x$author,
x$city,
x$country,
x$category,)
for (i in categories) {
print(i)
eval(parse(text = paste0('mydf$',i,' <- rep(FALSE,length(x$category))')))
}
# load true for every language in inserat
for(i in 1:length(x$category)){
ls = strsplit(x$category[i],split = ";")
for(cat in ls[[1]]){
if(cat %in% categories){
eval(parse(text = paste0('mydf$',cat,'[',i,'] <- TRUE')))
}
}
}
# perform Assiociation Rules
rules_all <- apriori(mydf,
parameter = list(supp = 0.1, conf = 0.1, target = "rules"),
# lhs -> target input classes, rhs -> target output classes
#appearance = list(rhs=c("python"))
)
inspect(rules_all)
library(sparklyr)
library(dplyr)
library(stringr)
library(arules)
setwd("/Users/michaelstedler/PycharmProjects/BigDataProject")
# Spark Configurations
conf <- spark_config()
# build SPARK Connection
sc <- spark_connect(master = "local")
# load dataframe
jobsFeed <- read.csv("data/jobsFeed.csv")
tbl_jobsFeed <- copy_to(sc,jobsFeed,name=spark_table_name(substitute(jobsFeed)))
#
x <- tbl_jobsFeed %>%
#filter(city=="BERLIN") %>%
select(author,category,city,country)%>%
collect()
# build list with all categories in filtered jobsFeed
categories <- c()
for(i in 1:length(x$category)){
ls = strsplit(x$category[i],split = ";")
for(cat in ls[[1]]){
if(!cat %in% categories){
categories <-c(categories,str_replace_all(cat,"[^[:alnum:]]",""))
}
}
}
# create columns for every possible language
mydf <- data.frame(x$author,
x$city,
x$country,
x$category)
for (i in categories) {
print(i)
eval(parse(text = paste0('mydf$',i,' <- rep(FALSE,length(x$category))')))
}
# load true for every language in inserat
for(i in 1:length(x$category)){
ls = strsplit(x$category[i],split = ";")
for(cat in ls[[1]]){
if(cat %in% categories){
eval(parse(text = paste0('mydf$',cat,'[',i,'] <- TRUE')))
}
}
}
# perform Assiociation Rules
rules_all <- apriori(mydf,
parameter = list(supp = 0.1, conf = 0.1, target = "rules"),
# lhs -> target input classes, rhs -> target output classes
#appearance = list(rhs=c("python"))
)
inspect(rules_all)
library(sparklyr)
library(dplyr)
library(stringr)
library(arules)
setwd("/Users/michaelstedler/PycharmProjects/BigDataProject")
# Spark Configurations
conf <- spark_config()
# build SPARK Connection
sc <- spark_connect(master = "local")
# load dataframe
jobsFeed <- read.csv("data/jobsFeed.csv")
tbl_jobsFeed <- copy_to(sc,jobsFeed,name=spark_table_name(substitute(jobsFeed)))
#
x <- tbl_jobsFeed %>%
#filter(city=="BERLIN") %>%
select(author,category,city,country)%>%
collect()
# build list with all categories in filtered jobsFeed
categories <- c()
for(i in 1:length(x$category)){
ls = strsplit(x$category[i],split = ";")
for(cat in ls[[1]]){
if(!cat %in% categories){
categories <-c(categories,str_replace_all(cat,"[^[:alnum:]]",""))
}
}
}
# create columns for every possible language
mydf <- data.frame(x$author,
x$city,
x$country,
x$category)
for (i in categories) {
print(i)
eval(parse(text = paste0('mydf$',i,' <- rep(FALSE,length(x$category))')))
}
# load true for every language in inserat
for(i in 1:length(x$category)){
ls = strsplit(x$category[i],split = ";")
for(cat in ls[[1]]){
if(cat %in% categories){
eval(parse(text = paste0('mydf$',cat,'[',i,'] <- TRUE')))
}
}
}
# perform Assiociation Rules
rules_all <- apriori(mydf,
parameter = list(supp = 0.1,
conf = 0.1,
target = "rules",
minlen=2),
# lhs -> target input classes, rhs -> target output classes
#appearance = list(rhs=c("python"))
)
inspect(rules_all)
library(sparklyr)
library(dplyr)
library(stringr)
library(arules)
setwd("/Users/michaelstedler/PycharmProjects/BigDataProject")
# Spark Configurations
conf <- spark_config()
# build SPARK Connection
sc <- spark_connect(master = "local")
# load dataframe
jobsFeed <- read.csv("data/jobsFeed.csv")
tbl_jobsFeed <- copy_to(sc,jobsFeed,name=spark_table_name(substitute(jobsFeed)))
#
x <- tbl_jobsFeed %>%
#filter(city=="BERLIN") %>%
select(author,category,city,country)%>%
collect()
# build list with all categories in filtered jobsFeed
categories <- c()
for(i in 1:length(x$category)){
ls = strsplit(x$category[i],split = ";")
for(cat in ls[[1]]){
if(!cat %in% categories){
categories <-c(categories,str_replace_all(cat,"[^[:alnum:]]",""))
}
}
}
# create columns for every possible language
mydf <- data.frame(x$author,
x$city,
x$country,
x$category)
for (i in categories) {
print(i)
eval(parse(text = paste0('mydf$',i,' <- rep(FALSE,length(x$category))')))
}
# load true for every language in inserat
for(i in 1:length(x$category)){
ls = strsplit(x$category[i],split = ";")
for(cat in ls[[1]]){
if(cat %in% categories){
eval(parse(text = paste0('mydf$',cat,'[',i,'] <- TRUE')))
}
}
}
# perform Assiociation Rules
rules_all <- apriori(mydf,
parameter = list(supp = 0.05,
conf = 0.05,
target = "rules",
minlen=2),
# lhs -> target input classes, rhs -> target output classes
#appearance = list(rhs=c("python"))
)
inspect(rules_all)
